{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process blog post:\n",
    "\n",
    "Like so many others out there this quarantine has instilled a certain level of wanderlust in me. And obviously before I commit to any location I wanted to know that I'm not getting scalped on the airfare. To put my (and possibly your) mind at ease I've looked at historical airfare prices across X popular routes to get a view on the price fluctiations you can expect if you're travelling.\n",
    "\n",
    "## Table of Contents:\n",
    "0. Exec summary\n",
    "1. Data collection\n",
    "    - Schema and collection method\n",
    "    - Sources\n",
    "        - Airports & Routes\n",
    "        - Flights & Prices\n",
    "2. Data preparation and feature engineering\n",
    "    - TBC\n",
    "3. Model generation\n",
    "4. Model validation\n",
    "5. Output and visualizations\n",
    "6. Extensions\n",
    "\n",
    "## To do:\n",
    "Updates for streamlining:\n",
    "- collect regional mapping table of ICAO codes (e.g first letter K = USA)\n",
    "- collect airline IATA codes\n",
    "- possible additional data collection\n",
    "    - aircraft codes\n",
    "    - public aviation registers (# planes and type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-structuring airport and supplements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all the csv files\n",
    "airports = pd.read_csv(\"data/airports.csv\")\n",
    "destinations = pd.read_csv(\"data/destinations.csv\")\n",
    "basics = pd.read_csv(\"data/basics.csv\")\n",
    "frequency = pd.read_csv(\"data/frequency.csv\")\n",
    "runways = pd.read_csv(\"data/runway.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated URLS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport</th>\n",
       "      <th>Type</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>FAA</th>\n",
       "      <th>URL</th>\n",
       "      <th>check_country_comparison</th>\n",
       "      <th>check_url_country</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airport, Type, City, Country, IATA, ICAO, FAA, URL, check_country_comparison, check_url_country, check]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data integrity checks\n",
    "airports[\"check_country_comparison\"] = airports[\"Country\"].str.replace(\" \", \"-\").str.lower()\n",
    "airports[\"check_url_country\"] = airports[\"URL\"].str.split(\"/\").str[1]\n",
    "airports[\"check\"] = airports[\"check_country_comparison\"] != airports[\"check_url_country\"]\n",
    "\n",
    "# discrepancies to check\n",
    "airports[airports[\"check\"]].groupby([\"check_url_country\", \"check_country_comparison\"]).count()\n",
    "\n",
    "# duplicate URLs\n",
    "print(f\"There are { sum(airports.duplicated('URL')) } duplicated URLS\")\n",
    "airports[airports.duplicated(\"URL\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join key\n",
    "join_key = [\"Country\", \"Airport\", \"City\"]\n",
    "id_codes = [\"IATA\", \"ICAO\", \"FAA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag duplicate by unique key\n",
    "basics_dups = basics.groupby(join_key).count()[basics.groupby(join_key).count()[\"Metric\"]>6]\n",
    "airports[\"flag_duplicate_key\"] = airports.duplicated(join_key)\n",
    "\n",
    "# flag duplicate id codes in airports\n",
    "airports[\"flag_duplicate_anycode\"] = False\n",
    "for code in id_codes:\n",
    "    airports[f\"flag_duplicate_{code}\"] = airports.duplicated(code) & airports[code].notna()\n",
    "    airports[\"flag_duplicate_anycode\"] = airports[\"flag_duplicate_anycode\"] | airports[f\"flag_duplicate_{code}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IATA 1402 0 0\n",
      "ICAO 9254 0 0\n",
      "FAA 10174 0 0\n"
     ]
    }
   ],
   "source": [
    "# basics joins into main table to add long/lat/timezone\n",
    "basics_t = (basics\n",
    "            .drop_duplicates(subset=join_key+[\"Metric\"], keep=\"first\") # need to find better solution to this\n",
    "            .set_index(join_key + [\"Metric\"])['Value']\n",
    "            .unstack()\n",
    "            .reset_index()\n",
    "           )\n",
    "\n",
    "airports_to_merge = airports[(airports[\"flag_duplicate_key\"]==False) & (airports[\"flag_duplicate_anycode\"]==False)]\n",
    "master_airports = pd.merge(airports_to_merge, basics_t, how=\"left\", on=join_key, suffixes=[\"\", \"\"])\n",
    "\n",
    "# check IATA, ICAO, FAA codes are the same\n",
    "to_drop = list(master_airports.columns[master_airports.columns.str[:5] == \"check\"])\n",
    "master_airports.loc[master_airports[\"ICAO Code\"]==\"\\n\", \"ICAO Code\"] = np.nan\n",
    "\n",
    "for code in id_codes:\n",
    "    master_airports[f\"flag_{code}_discrepancy\"] = master_airports[code].fillna(\"N/A\") != master_airports[f\"{code} Code\"].fillna(\"N/A\")\n",
    "    master_airports[f\"{code}_master\"] = np.where(master_airports[code].isna(), master_airports[f\"{code} Code\"], master_airports[code])\n",
    "    \n",
    "    print(code, \n",
    "          sum(master_airports[f\"flag_{code}_discrepancy\"]), # number discrepancies\n",
    "          sum((master_airports[f\"flag_{code}_discrepancy\"]) & (master_airports[f\"{code} Code\"].notna())), # of which are due to nan\n",
    "          sum(master_airports[f\"{code}_master\"].isna()) - sum(master_airports[code].isna()) # gaps filled\n",
    "         ) \n",
    "    \n",
    "    to_drop.extend([f\"flag_{code}_discrepancy\", f\"{code} Code\", code])\n",
    "    \n",
    "# drop extra columns\n",
    "master_airports.drop(columns = to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_counts = destinations.groupby(join_key).size().reset_index(name='nRoutes')\n",
    "master_airports = pd.merge(master_airports, \n",
    "                           dest_counts, \n",
    "                           how=\"left\", \n",
    "                           on=join_key)\n",
    "\n",
    "# theres a fair number of airports without routes. Imagine this is due to being small so no regular commerical flights\n",
    "# implication there is that there are charter flights or flights run by small operators going to these airports (OOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the routes table\n",
    "airports_selected = (master_airports[join_key + [code + \"_master\" for code in id_codes]]\n",
    "                     .rename(columns={code + \"_master\": code + \"_Source\" for code in id_codes}))\n",
    "routes = pd.merge(destinations, \n",
    "                  airports_selected, \n",
    "                  how=\"left\", \n",
    "                  on=join_key, \n",
    "                  suffixes=[\"\", \"_Source\"])\n",
    "\n",
    "airports_selected = (airports_selected[airports_selected[\"IATA_Source\"].notna()]\n",
    "                   .rename(columns={code + \"_Source\": code for code in id_codes}))\n",
    "routes = pd.merge(routes, \n",
    "                  airports_selected.rename(columns={code + \"_Source\": code for code in id_codes}),\n",
    "                  how=\"left\", \n",
    "                  left_on=[\"IATA\"], # remember to change later to add city\n",
    "                  right_on=[\"IATA\"], \n",
    "                  suffixes=[\"\", \"_Dest\"])\n",
    "\n",
    "routes.rename(columns={code: code + \"_Dest\" for code in id_codes}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32308"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many routes can realistically look at prices for\n",
    "len(routes[(routes[\"IATA_Source\"].notna()) & (routes[\"IATA_Dest\"].notna())].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skyscanner flights\n",
    "\n",
    "Purpose of this section is to explore the data structure of the Skyscanner API and create an ETL pipeline that will periodically (daily) add historical prices to an SQLlite DB.\n",
    "\n",
    "Taking the airports and routes gather from the previous section, I now build up an updating view of the prices for those routes by airline. The value of the time series is to be able to look at how the time-till-flight (TTF) affects the price of the ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the Skyscanner code for each airport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query SQLite for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the routes have been structured for mass API quering, I iterate through the combinations to find the day's flight prices. \n",
    "\n",
    "N.B. Automate this to happen every day at X time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(origin, dest, date_outbound, date_inbound, country, currency, locale):\n",
    "    return f\"https://skyscanner-skyscanner-flight-search-v1.p.rapidapi.com/apiservices/browsedates/v1.0/{country}/{currency}/{locale}/{origin}/{dest}/{date_outbound}\"\n",
    "\n",
    "\n",
    "def make_call(origin, dest, date_outbound, date_inbound, country = \"UK\", currency = \"GBP\", locale = \"en-UK\"):\n",
    "    url = create_url(origin, dest, date_outbound, date_inbound, country, currency, locale)\n",
    "    \n",
    "    querystring = {\"inboundpartialdate\":date_inbound}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-host': \"skyscanner-skyscanner-flight-search-v1.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': \"\"\n",
    "        }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    response_json = json.loads(response.text)\n",
    "    print(json.dumps(response_json, indent=2))\n",
    "    return response_json\n",
    "\n",
    "def flatten_json(quotes):\n",
    "    for i, _ in enumerate(quotes['Quotes']):\n",
    "        \n",
    "        for key, val in quotes['Quotes'][i]['OutboundLeg'].items():\n",
    "            quotes['Quotes'][i][key] = val\n",
    "            \n",
    "        del(quotes['Quotes'][i]['OutboundLeg'])\n",
    "        \n",
    "    # json to DataFrames\n",
    "    # for each then need to enforce data types as well as rename any relevant columns \n",
    "    carriers = pd.DataFrame.from_dict(quotes['Carriers'])\n",
    "    \n",
    "    places = pd.DataFrame.from_dict(quotes['Places'])\n",
    "            \n",
    "    quotes = pd.DataFrame.from_dict(quotes['Quotes'])\n",
    "    \n",
    "    # construct routes from unique quotes start/end destinations\n",
    "    routes = pd.DataFrame.from_dict(quotes['Quotes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data schema\n",
    "\n",
    "    1. Carrier level\n",
    "        - Carrier ID\n",
    "        - Carrier Name\n",
    "        - Carrier Parent?\n",
    "        - Carrier Country\n",
    "        - Other flags ...\n",
    "        \n",
    "    2. Route level (includes layovers)\n",
    "        - Route ID\n",
    "        - Start airport\n",
    "        - End airport\n",
    "        \n",
    "    3. Airport level\n",
    "        - Airport ID\n",
    "        - Airport Name\n",
    "        - Airport Country\n",
    "        - Geo tag? lat and long?\n",
    "            - possibly important if want to look at catchment analysis later on\n",
    "           \n",
    "    4. Quote level (route & carrier & time level)\n",
    "        - Departure time\n",
    "        - Landing time / duration??\n",
    "        - Carrier ID\n",
    "        - Route id\n",
    "        - Price\n",
    "        - Direct or not flag\n",
    "        - Layover time?\n",
    "        - Layover cities (how do I store this?)\n",
    "        - Currency - GBP\n",
    "        - Quote time - when was this queried\n",
    "        - Sourcing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrier_ID =  1\n",
      "Carrier_Name =  British Airways\n",
      "Country =  UK\n",
      "Carrier_ID =  2\n",
      "Carrier_Name =  Virgin Airways\n",
      "Country =  UK\n"
     ]
    }
   ],
   "source": [
    "# create SQLLite DB and make schema\n",
    "\n",
    "#!/usr/bin/python\n",
    "# API Call key and meta data\n",
    "\n",
    "# # quotes = make_call(\"LHR-sky\", \"LAX- sky\", \"2020-10-01\", \"2020-11-01\")\n",
    "# df = pd.DataFrame.from_dict(quotes)\n",
    "# head(df)\n",
    "\n",
    "\n",
    "conn = sqlite3.connect('test.db')\n",
    "\n",
    "field = [\"Carrier_ID\", \"Carrier_Name\", \"Country\"]\n",
    "\n",
    "conn.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS CARRIER\n",
    "                (CARRIER_ID INT PRIMARY KEY     NOT NULL,\n",
    "                 CARRIER_NAME           TEXT    NOT NULL,\n",
    "                 COUNTRY                TEXT    NOT NULL);''')\n",
    "\n",
    "conn.execute(\"INSERT INTO CARRIER (CARRIER_ID,CARRIER_NAME,COUNTRY) \\\n",
    "      VALUES (2, 'Virgin Airways', 'UK')\");\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cursor = conn.execute(\"SELECT carrier_id, carrier_name, country from CARRIER\")\n",
    "for row in cursor:\n",
    "    for i, val in enumerate(row):\n",
    "        print(f\"{field[i]} = \", val)\n",
    "\n",
    "conn.close()\n",
    "# back up function that recreates the schema on deletion\n",
    "\n",
    "# take json format and put into relational database\n",
    "\n",
    "# append to SQLLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARRIER',)\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('test.db')\n",
    "\n",
    "# print out all tables in database\n",
    "cursor = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "for row in cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # to get new quotes for each combination of date, origin, dest\n",
    "    for origin, dest, date_outbound, date_inbound in search_params:\n",
    "        quotes = make_call(origin, dest, date_outbound, date_inbound)\n",
    "        \n",
    "        quotes = prepare(quotes)\n",
    "        connection = make_connection()\n",
    "        update_database(connection, quotes)\n",
    "\n",
    "\n",
    "        \n",
    "def prepare():\n",
    "    pass\n",
    "        \n",
    "def make_connection():\n",
    "    pass\n",
    "        \n",
    "def update_database(connection, json):\n",
    "    '''\n",
    "    Update SQLite tables with new json\n",
    "    '''\n",
    "    if not json:\n",
    "        # add to data validation (date check?)\n",
    "        print(\"No new data, exiting update\")\n",
    "        \n",
    "    updates = [update_carriers, update_routes, update_airports, update_quotes]\n",
    "    for update in updates:\n",
    "        print(update(connection, json))\n",
    "        \n",
    "        \n",
    "def update_carriers():\n",
    "    # connect to table\n",
    "    # insert\n",
    "    # try catch?\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
